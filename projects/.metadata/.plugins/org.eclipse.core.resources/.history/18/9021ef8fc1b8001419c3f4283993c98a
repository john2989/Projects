package stubs;
import java.io.IOException;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.MapWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class MaxReducer2 extends Reducer<Text, String, Text, String> {
  IntWritable intWritable=new IntWritable(1);
 
  Text text=new Text();
  String output = "";

  @Override
  public void reduce(Text key, Iterable<String> values, Context context)
      throws IOException, InterruptedException {
	
	int maxLength=0;
	String maxWord ="";
    for (String value : values) {
    	String[] splitValues = value.split(",");
    	int length = Integer.parseInt(splitValues[1]);
    	if(length > maxLength){
    		maxLength = length;
    		maxWord = splitValues[0];
    	}
    }
    
    output = maxLength + " " + maxWord;
 
    context.write(text, output);

  }
}